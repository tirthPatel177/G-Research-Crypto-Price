{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import time \nimport traceback\nfrom datetime import datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\nfrom lightgbm import LGBMRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T16:43:26.962254Z","iopub.execute_input":"2022-04-21T16:43:26.962907Z","iopub.status.idle":"2022-04-21T16:43:29.384886Z","shell.execute_reply.started":"2022-04-21T16:43:26.962771Z","shell.execute_reply":"2022-04-21T16:43:29.384225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Datasets","metadata":{}},{"cell_type":"code","source":"data_folder = \"../input/time-series-crypto-forecasting/\"\n!ls  $data_folder","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asset_details = pd.read_csv(data_folder + 'asset_details.csv')\nasset_details.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(data_folder + 'train.csv')\ndf_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(data_folder + 'test.csv')\ndf_test.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"code","source":"def upper_shadow(df):\n    return df['High'] - np.maximum(df['Close'], df['Open'])\ndef lower_shadow(df):\n    return np.minimum(df['Close'], df['Open']) - df['Low']\n\ndef get_features(df):\n    df_feat = df[['Count', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP']].copy()\n    df_feat['Upper_Shadow'] = upper_shadow(df_feat)\n    df_feat['Lower_Shadow'] = lower_shadow(df_feat)\n    return df_feat","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:48:22.543238Z","iopub.execute_input":"2022-04-21T09:48:22.543649Z","iopub.status.idle":"2022-04-21T09:48:22.554334Z","shell.execute_reply.started":"2022-04-21T09:48:22.543579Z","shell.execute_reply":"2022-04-21T09:48:22.553468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction\n\n","metadata":{}},{"cell_type":"markdown","source":"## Without tuning","metadata":{}},{"cell_type":"code","source":"def get_Xy_and_model_for_asset(df_train, asset_id):\n    df = df_train[df_train[\"Asset_ID\"] == asset_id]\n    \n    df_proc = get_features(df)\n    df_proc['y'] = df['Target']\n    df_proc.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df_proc = df_proc.dropna(how=\"any\")\n    \n    X = df_proc.drop(\"y\", axis=1)\n    y = df_proc[\"y\"]   \n    \n    model = LGBMRegressor()\n    model.fit(X, y)\n    \n    return X, y, model","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:48:55.010987Z","iopub.execute_input":"2022-04-21T09:48:55.011618Z","iopub.status.idle":"2022-04-21T09:48:55.017447Z","shell.execute_reply.started":"2022-04-21T09:48:55.011557Z","shell.execute_reply":"2022-04-21T09:48:55.016727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fitting","metadata":{}},{"cell_type":"code","source":"Xs = {}\nys = {}\nnon_tuned_models = {}\n\nfor asset_id, asset_name in zip(asset_details['Asset_ID'], asset_details['Asset_Name']):\n    print(f\"Training model for {asset_name:<16} (ID={asset_id:<2})\")\n    X, y, model = get_Xy_and_model_for_asset(df_train, asset_id)\n    \n    try:\n        Xs[asset_id], ys[asset_id], non_tuned_models[asset_id] = X, y, model\n    except: \n        Xs[asset_id], ys[asset_id], non_tuned_models[asset_id] = None, None, None ","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:48:56.499565Z","iopub.execute_input":"2022-04-21T09:48:56.500307Z","iopub.status.idle":"2022-04-21T09:49:58.594545Z","shell.execute_reply.started":"2022-04-21T09:48:56.500261Z","shell.execute_reply":"2022-04-21T09:49:58.59385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pedicting","metadata":{}},{"cell_type":"code","source":"df_non_tuned_pred = []\n\nfor j , row in df_test.iterrows():     \n    if(j%100000 == 0): \n        print('100000 complete ...')\n    if non_tuned_models[row['Asset_ID']] is not None:\n        model = non_tuned_models[row['Asset_ID']]\n        x_test = get_features(row)\n        y_pred = model.predict(pd.DataFrame([x_test]))[0]\n        df_non_tuned_pred.append(y_pred)\n    else:       \n        df_non_tuned_pred.append(0)    \n        \npd.DataFrame(df_non_tuned_pred).to_csv('non_tuned_predicted.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## With Tuning","metadata":{}},{"cell_type":"code","source":"hyperparams = [\n    [0.01, 111],\n    [0.01, -1],\n    [0.05, 151],\n    [0.01, 141],\n    [0.01, 41],\n    [-1, 51],\n    [0.05, 21],\n    [0.05, -1],\n    [0.01, 61],\n    [0.05, 41],\n    [0.05, 21],\n    [0.01, 71],\n    [0.01, 61],\n    [0.01, 21]\n]\n\ndef get_tuned_Xy_and_model_for_asset(df_train, asset_id, idx):\n    df = df_train[df_train[\"Asset_ID\"] == asset_id]\n    \n    df_proc = get_features(df)\n    df_proc['y'] = df['Target']\n    df_proc.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df_proc = df_proc.dropna(how=\"any\")\n    \n    X = df_proc.drop(\"y\", axis=1)\n    y = df_proc[\"y\"]   \n    \n    if(hyperparams[idx][0] != -1 and hyperparams[idx][1] != -1):\n        model = LGBMRegressor(learning_rate=hyperparams[idx][0], num_leaves=hyperparams[idx][1])\n    else:\n        if(hyperparams[idx][0] == -1):\n            model = LGBMRegressor(num_leaves=hyperparams[idx][1])\n        else:\n            model = LGBMRegressor(learning_rate=hyperparams[idx][0])\n    model.fit(X, y)\n    return X, y, model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T12:40:49.685222Z","iopub.execute_input":"2022-04-21T12:40:49.685679Z","iopub.status.idle":"2022-04-21T12:40:49.720239Z","shell.execute_reply.started":"2022-04-21T12:40:49.68556Z","shell.execute_reply":"2022-04-21T12:40:49.719364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fitting","metadata":{}},{"cell_type":"code","source":"Xs = {}\nys = {}\nmodels = {}\n\ncount = 0\n\nfor asset_id, asset_name in zip(asset_details['Asset_ID'], asset_details['Asset_Name']):\n    print(f\"Training model for {asset_name:<16} (ID={asset_id:<2})\")\n    X, y, model = get_tuned_Xy_and_model_for_asset(df_train, asset_id, count)\n    \n    count += 1\n    try:\n        Xs[asset_id], ys[asset_id], models[asset_id] = X, y, model\n    except: \n        Xs[asset_id], ys[asset_id], models[asset_id] = None, None, None ","metadata":{"execution":{"iopub.status.busy":"2022-04-20T09:02:13.094041Z","iopub.execute_input":"2022-04-20T09:02:13.094629Z","iopub.status.idle":"2022-04-20T09:03:08.980334Z","shell.execute_reply.started":"2022-04-20T09:02:13.09458Z","shell.execute_reply":"2022-04-20T09:03:08.979635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting","metadata":{}},{"cell_type":"code","source":"df_tuned_pred = []\n\nfor j , row in df_test.iterrows():     \n    if(j%100000 == 0): \n        print('100000 complete ...')\n    if models[row['Asset_ID']] is not None:\n        model = models[row['Asset_ID']]\n        x_test = get_features(row)\n        y_pred = model.predict(pd.DataFrame([x_test]))[0]\n        df_tuned_pred.append(y_pred)\n    else:       \n        df_tuned_pred.append(0)    \n        \npd.DataFrame(df_tuned_pred).to_csv('tuned_predicted.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scratch: script for fine tuning using GRID search","metadata":{}},{"cell_type":"code","source":"# parameters = {\n#     'max_depth': range (2, 10, 1),\n#     'num_leaves': range(21, 161, 10),\n#     'learning_rate': [0.1, 0.01, 0.05]\n# }\n\n# new_models = {}\n\n# for asset_id, asset_name in zip(df_asset_details['Asset_ID'], df_asset_details['Asset_Name']):\n#     print(\"GridSearchCV for: \" + asset_name)\n    \n#     grid_search = GridSearchCV(\n#         estimator=get_Xy_and_model_for_asset(df_train, asset_id)[2], \n#         param_grid=parameters,\n#         n_jobs = -1,\n#         cv = 5,\n#         verbose=True\n#     )\n    \n#     grid_search.fit(Xs[asset_id], ys[asset_id])\n#     new_models[asset_id] = grid_search.best_estimator_\n#     grid_search.best_estimator_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for asset_id, asset_name in zip(df_asset_details['Asset_ID'], df_asset_details['Asset_Name']):\n#     print(f\"Tuned model for {asset_name:<1} (ID={asset_id:})\")\n#     print(new_models[asset_id])","metadata":{},"execution_count":null,"outputs":[]}]}